{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjWS6L77fjT+Z1BvWL53DD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfukagaw28/ColabNotebooks/blob/main/%E9%9D%92%E7%A9%BA%E6%96%87%E5%BA%AB%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86%E6%B8%88%E3%81%BF%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 青空文庫の前処理済みテキストデータを利用する"
      ],
      "metadata": {
        "id": "v3ptjF49aw7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "青空文庫のテキストデータををテキストマイニングや言語モデルの学習等の目的で利用する際には，ルビや注記などのノイズとなるものを除去するための前処理が必要です。\n",
        "\n",
        "前処理済みの青空文庫テキストデータが Hugging Face 上で公開されています（ちょうど２年前頃。もう少し早く知りたかった）。\n",
        "\n",
        "*   https://huggingface.co/datasets/globis-university/aozorabunko-clean\n",
        "*   [青空文庫のテキストから作成したコーパスを Hugging Face で公開しました #LLM - Qiita](https://qiita.com/akeyhero/items/b53eae1c0bc4d54e321f)"
      ],
      "metadata": {
        "id": "U-lcot_wa0F6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hugging Face](https://huggingface.co/)（ハギングフェイス）とは、自然言語処理（NLP）や機械学習（ML）分野で広く利用されているオープンソースプラットフォーム兼コミュニティです。\n",
        "\n",
        "音声・画像・テキストなどのデータセットや，自然言語モデル BERT やその変種・改良版などが Hugging Face 上で公開されており，誰でも利用することができます。\n",
        "また，新たなデータセットやモデルを誰でも公開することができます。\n",
        "\n",
        "Python で Hugging Face 状のデータセットを利用するには，Hugging Face が公開している Python ライブラリ [datasets](https://pypi.org/project/datasets/) を利用するのが便利です。Google Colab のランタイムには，この datasets が最初からインストールされており，追加インストール不要で import することができます（2025年10月時点）。"
      ],
      "metadata": {
        "id": "mLN_BtkBeOvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title データセットを読み込む\n",
        "from datasets import load_dataset\n",
        "ds = load_dataset('globis-university/aozorabunko-clean')"
      ],
      "metadata": {
        "id": "ZpGjByK7gNr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データセット\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-smeYgChBzk",
        "outputId": "2e50f8b7-ea2a-472a-ce49-bf0cc5cd537a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'footnote', 'meta'],\n",
              "        num_rows: 16951\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練用データ\n",
        "ds['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlouOUHqhNUm",
        "outputId": "a5f84d20-e70b-499a-bfd9-f4bc8405233f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'footnote', 'meta'],\n",
              "    num_rows: 16951\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1つの作品を抽出する\n",
        "book = ds['train'][0]\n",
        "book['meta']['作品名']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QJcNstXOhB2Z",
        "outputId": "0e59e276-f380-4e85-b3d5-cfb3dba61c04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ウェストミンスター寺院'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1つの作品のテキストデータを抽出する\n",
        "text = book['text']\n",
        "print(f'テキストの文字数: {len(text)}')\n",
        "print()\n",
        "print('テキストの先頭100文字:')\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkSwuPOthB5e",
        "outputId": "e49c8bec-e479-4be4-8b4a-c8c43c52933c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テキストの文字数: 10639\n",
            "\n",
            "テキストの先頭100文字:\n",
            "深いおどろきにうたれて、\n",
            "名高いウェストミンスターに\n",
            "真鍮や石の記念碑となって\n",
            "すべての王侯貴族が集まっているのをみれば、\n",
            "今はさげすみも、ほこりも、見栄もない。\n",
            "善にかえった貴人の姿、\n",
            "華美と俗世の\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1つの作品のフッター情報（主にテキスト入力作業に関する情報）を抽出する\n",
        "print(book['footnote'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjGO6zrIhB8C",
        "outputId": "946fe152-53d5-47ac-8503-639d41173fdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "底本：「スケッチ・ブック」新潮文庫、新潮社\n",
            "　　　1957（昭和32）年5月20日発行\n",
            "　　　2000（平成12）年2月20日33刷改版\n",
            "※「寂莫」と「寂寞」の混在は、底本通りです。\n",
            "入力：えにしだ\n",
            "校正：砂場清隆\n",
            "2020年3月28日作成\n",
            "青空文庫作成ファイル：\n",
            "このファイルは、インターネットの図書館、青空文庫（https://www.aozora.gr.jp/）で作られました。入力、校正、制作にあたったのは、ボランティアの皆さんです。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title 作品の文字種別を抽出する\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "series = pd.Series([row['meta']['文字遣い種別'] for row in ds['train']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTYxopnxi_M9",
        "outputId": "17866a2c-69dc-4e82-df61-dc4f1c46e18c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.03 s, sys: 61.7 ms, total: 6.09 s\n",
            "Wall time: 6.14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文字遣い種別を集計する\n",
        "\n",
        "series.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "GjNvxI1oi_TY",
        "outputId": "2e677155-87b8-497c-9060-36768d88ed8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "新字新仮名    10246\n",
              "新字旧仮名     4515\n",
              "旧字旧仮名     2143\n",
              "旧字新仮名       32\n",
              "その他         15\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>新字新仮名</th>\n",
              "      <td>10246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>新字旧仮名</th>\n",
              "      <td>4515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>旧字旧仮名</th>\n",
              "      <td>2143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>旧字新仮名</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>その他</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 作品名で絞り込む\n",
        "\n",
        "# 作品名が「吾輩」で始まる作品を抽出する\n",
        "temp = ds.filter(lambda row: row['meta']['作品名'].startswith('吾輩'))\n",
        "\n",
        "print('ヒットした件数:', temp['train'].num_rows)\n",
        "\n",
        "book = temp['train'][0]"
      ],
      "metadata": {
        "id": "opzjiEUDnJnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book['meta']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVzXSTEni_WT",
        "outputId": "65e799d9-de61-41c3-b0ba-d8b2db3ac901"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'作品ID': '000789',\n",
              " '作品名': '吾輩は猫である',\n",
              " '作品名読み': 'わがはいはねこである',\n",
              " 'ソート用読み': 'わかはいはねこてある',\n",
              " '副題': '',\n",
              " '副題読み': '',\n",
              " '原題': '',\n",
              " '初出': '「ホトトギス」1905（明治38）年1月、2月、4月、6月、7月、10月、1906（明治39）年1月、3月、4月、8月',\n",
              " '分類番号': 'NDC 913',\n",
              " '文字遣い種別': '新字新仮名',\n",
              " '作品著作権フラグ': 'なし',\n",
              " '公開日': datetime.datetime(1999, 9, 21, 0, 0),\n",
              " '最終更新日': datetime.datetime(2018, 2, 5, 0, 0),\n",
              " '図書カードURL': 'https://www.aozora.gr.jp/cards/000148/card789.html',\n",
              " '人物ID': '000148',\n",
              " '姓': '夏目',\n",
              " '名': '漱石',\n",
              " '姓読み': 'なつめ',\n",
              " '名読み': 'そうせき',\n",
              " '姓読みソート用': 'なつめ',\n",
              " '名読みソート用': 'そうせき',\n",
              " '姓ローマ字': 'Natsume',\n",
              " '名ローマ字': 'Soseki',\n",
              " '役割フラグ': '著者',\n",
              " '生年月日': '1867-02-09',\n",
              " '没年月日': '1916-12-09',\n",
              " '人物著作権フラグ': 'なし',\n",
              " '底本名1': '夏目漱石全集1',\n",
              " '底本出版社名1': 'ちくま文庫、筑摩書房',\n",
              " '底本初版発行年1': '1987（昭和62）年9月29日',\n",
              " '入力に使用した版1': '1987（昭和62）年9月29日',\n",
              " '校正に使用した版1': '1994（平成6）年9月30日第4刷',\n",
              " '底本の親本名1': '筑摩全集類聚版\\u3000夏目漱石全集\\u30001',\n",
              " '底本の親本出版社名1': '筑摩書房',\n",
              " '底本の親本初版発行年1': '1971（昭和46）年4月5日',\n",
              " '底本名2': '',\n",
              " '底本出版社名2': '',\n",
              " '底本初版発行年2': '',\n",
              " '入力に使用した版2': '',\n",
              " '校正に使用した版2': '',\n",
              " '底本の親本名2': '',\n",
              " '底本の親本出版社名2': '',\n",
              " '底本の親本初版発行年2': '',\n",
              " '入力者': '柴田卓治',\n",
              " '校正者': '田尻幹二、高橋真也、しず、瀬戸さえ子、おのしげひこ、渡部峰子',\n",
              " 'テキストファイルURL': 'https://www.aozora.gr.jp/cards/000148/files/789_ruby_5639.zip',\n",
              " 'テキストファイル最終更新日': datetime.datetime(2018, 2, 5, 0, 0),\n",
              " 'テキストファイル符号化方式': 'ShiftJIS',\n",
              " 'テキストファイル文字集合': 'JIS X 0208',\n",
              " 'テキストファイル修正回数': '15',\n",
              " 'XHTML/HTMLファイルURL': 'https://www.aozora.gr.jp/cards/000148/files/789_14547.html',\n",
              " 'XHTML/HTMLファイル最終更新日': datetime.datetime(2018, 2, 5, 0, 0),\n",
              " 'XHTML/HTMLファイル符号化方式': 'ShiftJIS',\n",
              " 'XHTML/HTMLファイル文字集合': 'JIS X 0208',\n",
              " 'XHTML/HTMLファイル修正回数': '9'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## aozorahack/aozorabunko_text と比較する"
      ],
      "metadata": {
        "id": "AT7RRBsEpNHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "青空文庫公式プロジェクト「Code for 青空文庫」に由来するテキストデータセットである aozorahack/aozorabunko_text と比較する。\n",
        "\n",
        "*   Hugging Face の globis-university/aozorabunko-clean データセットについて\n",
        "    *   最終更新日時は 2023年7月頃\n",
        "    *   作品数は 16951\n",
        "*   aozorahack/aozorabunko_text データセットについて\n",
        "    *   最終更新日時は 2023年3月頃\n",
        "    *   作品数は 17436"
      ],
      "metadata": {
        "id": "B_8U9D_kpZ19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth=1 https://github.com/aozorahack/aozorabunko_text.git\n",
        "!find aozorabunko_text/cards -type f | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7mKQkRbq4Sl",
        "outputId": "bed2b71f-e72e-4383-9266-685b281c3d2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aozorabunko_text'...\n",
            "remote: Enumerating objects: 36894, done.\u001b[K\n",
            "remote: Counting objects: 100% (36894/36894), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17843/17843), done.\u001b[K\n",
            "remote: Total 36894 (delta 191), reused 36697 (delta 191), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36894/36894), 245.89 MiB | 18.26 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n",
            "Updating files: 100% (17442/17442), done.\n",
            "17436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "aozorahack/aozorabunko_text から『吾輩は猫である』のテキストデータを抽出して前処理を行う。"
      ],
      "metadata": {
        "id": "6388JSswsUXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 青空文庫のテキストデータをダウンロードする（neko1.txt）\n",
        "!curl -RLO https://github.com/aozorabunko/aozorabunko/raw/refs/heads/master/cards/000148/files/789_ruby_5639.zip\n",
        "!unzip -o 789_ruby_5639.zip wagahaiwa_nekodearu.txt\n",
        "!mv wagahaiwa_nekodearu.txt neko1.txt\n",
        "!rm -f 789_ruby_5639.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coa-optCr8ks",
        "outputId": "1f7489f2-a94a-4a04-8ec3-a7f1fbd8d1de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  336k  100  336k    0     0   701k      0 --:--:-- --:--:-- --:--:--  701k\n",
            "Archive:  789_ruby_5639.zip\n",
            "Made with MacWinZipper (http://tidajapan.com/macwinzipper)\n",
            "  inflating: wagahaiwa_nekodearu.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def aozora_preprocess(text):\n",
        "  # 冒頭の記載事項（タイトル・著者名等）を検出して除去する\n",
        "  try:\n",
        "    pos = text.index('\\n\\n')\n",
        "    text = text[pos+2:]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # 【テキスト中に現れる記号について】を検出して除去する\n",
        "  try:\n",
        "    # 最初の行が「--------」で始まることを確認する\n",
        "    assert text.startswith('--------')\n",
        "\n",
        "    # ２つ目の「--------」で始まる行と，その次の空行を除去する\n",
        "    pos = text.index('\\n') + 1\n",
        "    pos = text.index('--------', pos)\n",
        "    pos = text.index('\\n\\n', pos) + 2\n",
        "    text = text[pos:]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # 本文の末尾の情報（底本，入力・校正にかんする情報等）を検出して除去する\n",
        "  try:\n",
        "    pos = text.index('\\n\\n\\n\\n')\n",
        "    text = text[:pos]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # ルビに関する記述を削除する\n",
        "  text = re.sub('《.+?》', '', text)\n",
        "  text = re.sub('｜', '', text)\n",
        "\n",
        "  # 注記情報（レイアウト情報，入力者注等）を検出して削除する\n",
        "  text = re.sub(r'［＃.*?］', '', text)\n",
        "\n",
        "  # 文ごとに改行する\n",
        "  # text = re.sub('(。|？)', '\\1\\n', text)\n",
        "\n",
        "  # HORIZONTAL BAR (U+2015) を EM DASH (U+2014) に変換する\n",
        "  # text = text.replace('\\u2015', '\\u2014')\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "CLKrsYaNr8ne"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストデータを読み込む\n",
        "text1 = open('neko1.txt', encoding='cp932').read()\n",
        "\n",
        "# 前処理を適用する\n",
        "text1 = aozora_preprocess(text1)"
      ],
      "metadata": {
        "id": "0mKdHLCgr8qi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hugging Face 青空文庫のテキストデータをダウンロードする（neko2.txt）\n",
        "ds = load_dataset('globis-university/aozorabunko-clean')\n",
        "temp = ds.filter(lambda row: row['meta']['作品ID'] == '000789')\n",
        "assert temp['train'].num_rows == 1\n",
        "book = temp['train'][0]\n",
        "text2 = book['text']"
      ],
      "metadata": {
        "id": "u-YzlvYes0yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title ２つのテキストデータを比較する\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "matcher = SequenceMatcher(None, text1, text2)\n",
        "\n",
        "for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "  if tag != 'equal':\n",
        "    print(f\"{text1[i1:i2]}\\t{text2[j1:j2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEHyCy9ps01J",
        "outputId": "1836286d-f7ae-48bb-edf0-a63f6d61326b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "※\t譃\n",
            "※\t饀\n",
            "※\t蹰\n",
            "※\t燄\n",
            "※\t饍\n",
            "※\t炷\n",
            "※\t炷\n",
            "※\t炷\n",
            "※\t炷\n",
            "※\tㇶ\n",
            "※\tㇶ\n",
            "※\t橛\n",
            "※\t睜\n",
            "※\t蹰\n",
            "※※\t惝怳\n",
            "※\t媧\n",
            "※\t鄢\n",
            "※\t燄\n",
            "※\t戕\n",
            "※\t匇\n",
            "※\t餼\n",
            "※\t騃\n",
            "※\t噱\n",
            "※\t彘\n",
            "※\t惸\n",
            "※\t璆\n",
            "※\t泫\n",
            "※\t蛼\n",
            "※\t蛼\n",
            "※\t燄\n",
            "※\tㇶ\n",
            "※\t卺\n",
            "※\t燄\n",
            "CPU times: user 1min 19s, sys: 83.2 ms, total: 1min 19s\n",
            "Wall time: 1min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自前の前処理済みテキストとも比較する"
      ],
      "metadata": {
        "id": "7IeCK6qEw-HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 自前のテキストデータをダウンロードする（neko3.txt）\n",
        "!curl -RLO https://github.com/dfukagaw28/aozorabunko_text/raw/refs/heads/preprocess/cards/000148/files/789_ruby_5639/789_ruby_5639.txt\n",
        "!mv 789_ruby_5639.txt neko3.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3EET8WLxJjq",
        "outputId": "c1f48c44-9b73-4053-cd11-166ebd9fa7b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1088k  100 1088k    0     0  1346k      0 --:--:-- --:--:-- --:--:-- 1346k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LP2HgYgNxzaI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 追加の前処理\n",
        "\n",
        "def _preprocess(text):\n",
        "\n",
        "  # ルビに関する記述を削除する\n",
        "  text = re.sub('《.+?》', '', text)\n",
        "  text = re.sub('｜', '', text)\n",
        "\n",
        "  # 注記情報（レイアウト情報，入力者注等）を検出して削除する\n",
        "  text = re.sub(r'［＃.*?］', '', text)\n",
        "\n",
        "  # 前後の空白を除去する\n",
        "  text = text.strip()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "xXVRo2Uyx8ll"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストデータを読み込む\n",
        "text3 = open('neko3.txt', encoding='utf8').read()\n",
        "\n",
        "# 前処理を適用する\n",
        "text3 = _preprocess(text3)"
      ],
      "metadata": {
        "id": "1PadMliCxq_R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ２つのテキストは一致する\n",
        "assert text2 == text3"
      ],
      "metadata": {
        "id": "g6hj82-eyS-j"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}